[
  {
    "objectID": "Take-home_exercise/Take-home_exercise_2.html",
    "href": "Take-home_exercise/Take-home_exercise_2.html",
    "title": "Take-home_exercise_2",
    "section": "",
    "text": "In today’s globalized era, international trade is a key economic topic. Singapore, with its strong financial sector and vibrant port economy, is highly sensitive to global economic changes. As an international financial center and major transshipment hub, its prosperity is closely tied to international trade dynamics.\nGlobalization brings both opportunities and challenges to Singapore’s trade. Fluctuations in global demand, trade policies, and technological changes impact its trade volume, composition, and direction. Understanding these trends is crucial for policymakers to develop strategies and for local businesses to make decisions.\n\n\n\nThis study focuses on exploring and visualizing Singapore’s international trade data using R. By analyzing historical and current data, we aim to identify patterns, discover trends, analyze the future direction of trade, and suggest improvements to the data visualizations that are now available on the Singapore government website.\n\n\n\n\n\n\n123\n\npacman::p_load(readxl, tidyverse, lubridate)\n\n\n\n\nThe data is from Merchandise Trade. Department of Statistics Singapore, DOS, which contains two datasets:\n1. Merchandise Trade by Region/Market\n2. Merchandise Trade by Commodity Section/Division\nDataset 1 contains 3 tables:\n\n\n\n\n\n\n\nTable Number\nName\n\n\n\n\nSheet 1\nMerchandise Trade By Region And Selected Market (Imports)\n\n\nSheet 2\nMerchandise Trade By Region And Selected Market (Domestic Exports)\n\n\nSheet 3\nMerchandise Trade By Region And Selected Market (Re-Exports)\n\n\n\nDataset 2 contains 10 tables:\n\n\n\nTable Number\nName\n\n\n\n\nSheet 1\nCommodity(At Current Prices)\n\n\nSheet 2\nCommodity(At 2023 Prices)\n\n\nSheet 3\nMerchandise Imports By Commodity Division\n\n\nSheet 4\nMerchandise Imports Of Machinery And Equipment\n\n\nSheet 5\nMerchandise Exports By Commodity Division\n\n\nSheet 6\nMerchandise Exports Of Machinery And Equipment\n\n\nSheet 7\nDomestic Exports By Commodity Division\n\n\nSheet 8\nDomestic Exports Of Major Non-Oil Products\n\n\nSheet 9\nRe-Exports By Commodity Division\n\n\nSheet 10\nRe-Exports Of Machinery And Equipment\n\n\n\n\n\n\nBefore importing the data, since there are some descriptive statements in the original table, copy the original table, keep one copy of these descriptions and delete the other to prevent its interference with the R recognition data, and import the table after deleting them.\n\n\nImports_data &lt;- read_xlsx(\"data/outputFile.xlsx\", sheet = \"T1\")\n\n\nExports_data &lt;- read_xlsx(\"data/outputFile.xlsx\", sheet = \"T2\")\n\n\nRe_Exports_data &lt;- read_xlsx(\"data/outputFile.xlsx\", sheet = \"T3\")\n\n\n\n\n\nImports_data[duplicated(Imports_data), ]\n\n# A tibble: 0 × 266\n# ℹ 266 variables: Data Series &lt;chr&gt;, 2025 Jan &lt;dbl&gt;, 2024 Dec &lt;dbl&gt;,\n#   2024 Nov &lt;dbl&gt;, 2024 Oct &lt;dbl&gt;, 2024 Sep &lt;dbl&gt;, 2024 Aug &lt;dbl&gt;,\n#   2024 Jul &lt;dbl&gt;, 2024 Jun &lt;dbl&gt;, 2024 May &lt;dbl&gt;, 2024 Apr &lt;dbl&gt;,\n#   2024 Mar &lt;dbl&gt;, 2024 Feb &lt;dbl&gt;, 2024 Jan &lt;dbl&gt;, 2023 Dec &lt;dbl&gt;,\n#   2023 Nov &lt;dbl&gt;, 2023 Oct &lt;dbl&gt;, 2023 Sep &lt;dbl&gt;, 2023 Aug &lt;dbl&gt;,\n#   2023 Jul &lt;dbl&gt;, 2023 Jun &lt;dbl&gt;, 2023 May &lt;dbl&gt;, 2023 Apr &lt;dbl&gt;,\n#   2023 Mar &lt;dbl&gt;, 2023 Feb &lt;dbl&gt;, 2023 Jan &lt;dbl&gt;, 2022 Dec &lt;dbl&gt;, …\n\n\n\nExports_data[duplicated(Exports_data), ]\n\n# A tibble: 0 × 266\n# ℹ 266 variables: Data Series &lt;chr&gt;, 2025 Jan &lt;dbl&gt;, 2024 Dec &lt;dbl&gt;,\n#   2024 Nov &lt;dbl&gt;, 2024 Oct &lt;dbl&gt;, 2024 Sep &lt;dbl&gt;, 2024 Aug &lt;dbl&gt;,\n#   2024 Jul &lt;dbl&gt;, 2024 Jun &lt;dbl&gt;, 2024 May &lt;dbl&gt;, 2024 Apr &lt;dbl&gt;,\n#   2024 Mar &lt;dbl&gt;, 2024 Feb &lt;dbl&gt;, 2024 Jan &lt;dbl&gt;, 2023 Dec &lt;dbl&gt;,\n#   2023 Nov &lt;dbl&gt;, 2023 Oct &lt;dbl&gt;, 2023 Sep &lt;dbl&gt;, 2023 Aug &lt;dbl&gt;,\n#   2023 Jul &lt;dbl&gt;, 2023 Jun &lt;dbl&gt;, 2023 May &lt;dbl&gt;, 2023 Apr &lt;dbl&gt;,\n#   2023 Mar &lt;dbl&gt;, 2023 Feb &lt;dbl&gt;, 2023 Jan &lt;dbl&gt;, 2022 Dec &lt;dbl&gt;, …\n\n\n\nRe_Exports_data[duplicated(Re_Exports_data), ]\n\n# A tibble: 0 × 266\n# ℹ 266 variables: Data Series &lt;chr&gt;, 2025 Jan &lt;dbl&gt;, 2024 Dec &lt;dbl&gt;,\n#   2024 Nov &lt;dbl&gt;, 2024 Oct &lt;dbl&gt;, 2024 Sep &lt;dbl&gt;, 2024 Aug &lt;dbl&gt;,\n#   2024 Jul &lt;dbl&gt;, 2024 Jun &lt;dbl&gt;, 2024 May &lt;dbl&gt;, 2024 Apr &lt;dbl&gt;,\n#   2024 Mar &lt;dbl&gt;, 2024 Feb &lt;dbl&gt;, 2024 Jan &lt;dbl&gt;, 2023 Dec &lt;dbl&gt;,\n#   2023 Nov &lt;dbl&gt;, 2023 Oct &lt;dbl&gt;, 2023 Sep &lt;dbl&gt;, 2023 Aug &lt;dbl&gt;,\n#   2023 Jul &lt;dbl&gt;, 2023 Jun &lt;dbl&gt;, 2023 May &lt;dbl&gt;, 2023 Apr &lt;dbl&gt;,\n#   2023 Mar &lt;dbl&gt;, 2023 Feb &lt;dbl&gt;, 2023 Jan &lt;dbl&gt;, 2022 Dec &lt;dbl&gt;, …\n\n\nThe result shows no duplicate data.\n\n\n\n\nany(is.na(Imports_data))\n\n[1] FALSE\n\n\n\nany(is.na(Exports_data))\n\n[1] FALSE\n\n\n\nany(is.na(Re_Exports_data))\n\n[1] FALSE\n\n\nThe result shows no missing values.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvantages\nDisadvantages\n\n\n\n\nThe contrasting colors of the different years make it easy to identify the data as belonging to different years.\nSimilar colors are used for imports and exports in the same year, making it easy to identify data from the same year.\nThe use of bar charts results in less obvious trends in the data, and exports and imports are mixed together, making it harder to see trends in the data.\n\n\nTotal trade for each year is labeled to the right of the corresponding year, facilitating direct comparisons between years.\nDirect display of total trade per year does not show trends in total trade.\n\n\n\nThe improved sketch is as follows\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nconvert_to_annual &lt;- function(data) {\n  \n  data_row &lt;- data[1, ]\n  \n  col_names &lt;- colnames(data)\n  \n  time_col_names &lt;- col_names[-1]\n  \n  years &lt;- as.numeric(sub(\" .*\", \"\", time_col_names))\n  \n  valid_years &lt;- years &gt;= 2015 & years &lt;= 2024\n  valid_time_col_names &lt;- time_col_names[valid_years]\n  valid_data &lt;- data_row[ , -1][valid_years]\n  \n  data_df &lt;- data.frame(Year = years[valid_years], Value = as.numeric(valid_data))\n  \n  annual_data &lt;- aggregate(Value ~ Year, data = data_df, sum)\n  \n  return(annual_data)\n}\n\nimport_annual &lt;- convert_to_annual(Imports_data)\nexport_annual &lt;- convert_to_annual(Exports_data)\nre_export_annual &lt;- convert_to_annual(Re_Exports_data)\n\ncombined_export_annual &lt;- data.frame(\n  Year = export_annual$Year,\n  Value_Export = export_annual$Value + re_export_annual$Value\n)\n\nmerged_data &lt;- merge(import_annual, combined_export_annual, by = \"Year\")\n\nmerged_data$Total &lt;- merged_data$Value + merged_data$Value_Export\n\nmerged_data$Value &lt;- merged_data$Value / 1000\nmerged_data$Value_Export &lt;- merged_data$Value_Export / 1000\nmerged_data$Total &lt;- merged_data$Total / 1000\n\nggplot(merged_data, aes(x = Year)) +\n  geom_line(aes(y = Value, color = \"Imports\")) +\n  geom_line(aes(y = Value_Export, color = \"Exports\")) +\n  geom_line(aes(y = Total, color = \"Total Trade\")) +\n  geom_text(aes(y = Value, label = Value), vjust = -0.5, size = 3) +\n  geom_text(aes(y = Value_Export, label = Value_Export), vjust = 1.5, size = 3) +\n  geom_text(aes(y = Total, label = Total), vjust = -0.5, size = 3) +\n  labs(title = \"Annual Imports, Exports and Total Trade Trends (2015 - 2024)\",\n       x = \"Year\",\n       y = \"Billion Dollars\",\n       color = \"Data Series\") +\n  scale_x_continuous(breaks = seq(2015, 2024, 1)) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nExplanation\n\n\n\n\nReplacing the bar chart in the original figure with a line chart would better represent the trend of trade volume over time. At the same time, the value of total trade is also converted into a line chart to reflect the trend, and the specific value for each year is indicated."
  },
  {
    "objectID": "Take-home_exercise/Take-home_exercise_2.html#introduction",
    "href": "Take-home_exercise/Take-home_exercise_2.html#introduction",
    "title": "Take-home_exercise_2",
    "section": "",
    "text": "In today’s globalized era, international trade is a key economic topic. Singapore, with its strong financial sector and vibrant port economy, is highly sensitive to global economic changes. As an international financial center and major transshipment hub, its prosperity is closely tied to international trade dynamics.\nGlobalization brings both opportunities and challenges to Singapore’s trade. Fluctuations in global demand, trade policies, and technological changes impact its trade volume, composition, and direction. Understanding these trends is crucial for policymakers to develop strategies and for local businesses to make decisions.\n\n\n\nThis study focuses on exploring and visualizing Singapore’s international trade data using R. By analyzing historical and current data, we aim to identify patterns, discover trends, analyze the future direction of trade, and suggest improvements to the data visualizations that are now available on the Singapore government website."
  },
  {
    "objectID": "Take-home_exercise/Take-home_exercise_2.html#data-prepare",
    "href": "Take-home_exercise/Take-home_exercise_2.html#data-prepare",
    "title": "Take-home_exercise_2",
    "section": "",
    "text": "123\n\npacman::p_load(readxl, tidyverse, lubridate)\n\n\n\n\nThe data is from Merchandise Trade. Department of Statistics Singapore, DOS, which contains two datasets:\n1. Merchandise Trade by Region/Market\n2. Merchandise Trade by Commodity Section/Division\nDataset 1 contains 3 tables:\n\n\n\n\n\n\n\nTable Number\nName\n\n\n\n\nSheet 1\nMerchandise Trade By Region And Selected Market (Imports)\n\n\nSheet 2\nMerchandise Trade By Region And Selected Market (Domestic Exports)\n\n\nSheet 3\nMerchandise Trade By Region And Selected Market (Re-Exports)\n\n\n\nDataset 2 contains 10 tables:\n\n\n\nTable Number\nName\n\n\n\n\nSheet 1\nCommodity(At Current Prices)\n\n\nSheet 2\nCommodity(At 2023 Prices)\n\n\nSheet 3\nMerchandise Imports By Commodity Division\n\n\nSheet 4\nMerchandise Imports Of Machinery And Equipment\n\n\nSheet 5\nMerchandise Exports By Commodity Division\n\n\nSheet 6\nMerchandise Exports Of Machinery And Equipment\n\n\nSheet 7\nDomestic Exports By Commodity Division\n\n\nSheet 8\nDomestic Exports Of Major Non-Oil Products\n\n\nSheet 9\nRe-Exports By Commodity Division\n\n\nSheet 10\nRe-Exports Of Machinery And Equipment\n\n\n\n\n\n\nBefore importing the data, since there are some descriptive statements in the original table, copy the original table, keep one copy of these descriptions and delete the other to prevent its interference with the R recognition data, and import the table after deleting them.\n\n\nImports_data &lt;- read_xlsx(\"data/outputFile.xlsx\", sheet = \"T1\")\n\n\nExports_data &lt;- read_xlsx(\"data/outputFile.xlsx\", sheet = \"T2\")\n\n\nRe_Exports_data &lt;- read_xlsx(\"data/outputFile.xlsx\", sheet = \"T3\")\n\n\n\n\n\nImports_data[duplicated(Imports_data), ]\n\n# A tibble: 0 × 266\n# ℹ 266 variables: Data Series &lt;chr&gt;, 2025 Jan &lt;dbl&gt;, 2024 Dec &lt;dbl&gt;,\n#   2024 Nov &lt;dbl&gt;, 2024 Oct &lt;dbl&gt;, 2024 Sep &lt;dbl&gt;, 2024 Aug &lt;dbl&gt;,\n#   2024 Jul &lt;dbl&gt;, 2024 Jun &lt;dbl&gt;, 2024 May &lt;dbl&gt;, 2024 Apr &lt;dbl&gt;,\n#   2024 Mar &lt;dbl&gt;, 2024 Feb &lt;dbl&gt;, 2024 Jan &lt;dbl&gt;, 2023 Dec &lt;dbl&gt;,\n#   2023 Nov &lt;dbl&gt;, 2023 Oct &lt;dbl&gt;, 2023 Sep &lt;dbl&gt;, 2023 Aug &lt;dbl&gt;,\n#   2023 Jul &lt;dbl&gt;, 2023 Jun &lt;dbl&gt;, 2023 May &lt;dbl&gt;, 2023 Apr &lt;dbl&gt;,\n#   2023 Mar &lt;dbl&gt;, 2023 Feb &lt;dbl&gt;, 2023 Jan &lt;dbl&gt;, 2022 Dec &lt;dbl&gt;, …\n\n\n\nExports_data[duplicated(Exports_data), ]\n\n# A tibble: 0 × 266\n# ℹ 266 variables: Data Series &lt;chr&gt;, 2025 Jan &lt;dbl&gt;, 2024 Dec &lt;dbl&gt;,\n#   2024 Nov &lt;dbl&gt;, 2024 Oct &lt;dbl&gt;, 2024 Sep &lt;dbl&gt;, 2024 Aug &lt;dbl&gt;,\n#   2024 Jul &lt;dbl&gt;, 2024 Jun &lt;dbl&gt;, 2024 May &lt;dbl&gt;, 2024 Apr &lt;dbl&gt;,\n#   2024 Mar &lt;dbl&gt;, 2024 Feb &lt;dbl&gt;, 2024 Jan &lt;dbl&gt;, 2023 Dec &lt;dbl&gt;,\n#   2023 Nov &lt;dbl&gt;, 2023 Oct &lt;dbl&gt;, 2023 Sep &lt;dbl&gt;, 2023 Aug &lt;dbl&gt;,\n#   2023 Jul &lt;dbl&gt;, 2023 Jun &lt;dbl&gt;, 2023 May &lt;dbl&gt;, 2023 Apr &lt;dbl&gt;,\n#   2023 Mar &lt;dbl&gt;, 2023 Feb &lt;dbl&gt;, 2023 Jan &lt;dbl&gt;, 2022 Dec &lt;dbl&gt;, …\n\n\n\nRe_Exports_data[duplicated(Re_Exports_data), ]\n\n# A tibble: 0 × 266\n# ℹ 266 variables: Data Series &lt;chr&gt;, 2025 Jan &lt;dbl&gt;, 2024 Dec &lt;dbl&gt;,\n#   2024 Nov &lt;dbl&gt;, 2024 Oct &lt;dbl&gt;, 2024 Sep &lt;dbl&gt;, 2024 Aug &lt;dbl&gt;,\n#   2024 Jul &lt;dbl&gt;, 2024 Jun &lt;dbl&gt;, 2024 May &lt;dbl&gt;, 2024 Apr &lt;dbl&gt;,\n#   2024 Mar &lt;dbl&gt;, 2024 Feb &lt;dbl&gt;, 2024 Jan &lt;dbl&gt;, 2023 Dec &lt;dbl&gt;,\n#   2023 Nov &lt;dbl&gt;, 2023 Oct &lt;dbl&gt;, 2023 Sep &lt;dbl&gt;, 2023 Aug &lt;dbl&gt;,\n#   2023 Jul &lt;dbl&gt;, 2023 Jun &lt;dbl&gt;, 2023 May &lt;dbl&gt;, 2023 Apr &lt;dbl&gt;,\n#   2023 Mar &lt;dbl&gt;, 2023 Feb &lt;dbl&gt;, 2023 Jan &lt;dbl&gt;, 2022 Dec &lt;dbl&gt;, …\n\n\nThe result shows no duplicate data.\n\n\n\n\nany(is.na(Imports_data))\n\n[1] FALSE\n\n\n\nany(is.na(Exports_data))\n\n[1] FALSE\n\n\n\nany(is.na(Re_Exports_data))\n\n[1] FALSE\n\n\nThe result shows no missing values."
  },
  {
    "objectID": "Take-home_exercise/Take-home_exercise_2.html#evaluation-of-data-visualizations",
    "href": "Take-home_exercise/Take-home_exercise_2.html#evaluation-of-data-visualizations",
    "title": "Take-home_exercise_2",
    "section": "",
    "text": "Advantages\nDisadvantages\n\n\n\n\nThe contrasting colors of the different years make it easy to identify the data as belonging to different years.\nSimilar colors are used for imports and exports in the same year, making it easy to identify data from the same year.\nThe use of bar charts results in less obvious trends in the data, and exports and imports are mixed together, making it harder to see trends in the data.\n\n\nTotal trade for each year is labeled to the right of the corresponding year, facilitating direct comparisons between years.\nDirect display of total trade per year does not show trends in total trade.\n\n\n\nThe improved sketch is as follows\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nconvert_to_annual &lt;- function(data) {\n  \n  data_row &lt;- data[1, ]\n  \n  col_names &lt;- colnames(data)\n  \n  time_col_names &lt;- col_names[-1]\n  \n  years &lt;- as.numeric(sub(\" .*\", \"\", time_col_names))\n  \n  valid_years &lt;- years &gt;= 2015 & years &lt;= 2024\n  valid_time_col_names &lt;- time_col_names[valid_years]\n  valid_data &lt;- data_row[ , -1][valid_years]\n  \n  data_df &lt;- data.frame(Year = years[valid_years], Value = as.numeric(valid_data))\n  \n  annual_data &lt;- aggregate(Value ~ Year, data = data_df, sum)\n  \n  return(annual_data)\n}\n\nimport_annual &lt;- convert_to_annual(Imports_data)\nexport_annual &lt;- convert_to_annual(Exports_data)\nre_export_annual &lt;- convert_to_annual(Re_Exports_data)\n\ncombined_export_annual &lt;- data.frame(\n  Year = export_annual$Year,\n  Value_Export = export_annual$Value + re_export_annual$Value\n)\n\nmerged_data &lt;- merge(import_annual, combined_export_annual, by = \"Year\")\n\nmerged_data$Total &lt;- merged_data$Value + merged_data$Value_Export\n\nmerged_data$Value &lt;- merged_data$Value / 1000\nmerged_data$Value_Export &lt;- merged_data$Value_Export / 1000\nmerged_data$Total &lt;- merged_data$Total / 1000\n\nggplot(merged_data, aes(x = Year)) +\n  geom_line(aes(y = Value, color = \"Imports\")) +\n  geom_line(aes(y = Value_Export, color = \"Exports\")) +\n  geom_line(aes(y = Total, color = \"Total Trade\")) +\n  geom_text(aes(y = Value, label = Value), vjust = -0.5, size = 3) +\n  geom_text(aes(y = Value_Export, label = Value_Export), vjust = 1.5, size = 3) +\n  geom_text(aes(y = Total, label = Total), vjust = -0.5, size = 3) +\n  labs(title = \"Annual Imports, Exports and Total Trade Trends (2015 - 2024)\",\n       x = \"Year\",\n       y = \"Billion Dollars\",\n       color = \"Data Series\") +\n  scale_x_continuous(breaks = seq(2015, 2024, 1)) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nExplanation\n\n\n\n\nReplacing the bar chart in the original figure with a line chart would better represent the trend of trade volume over time. At the same time, the value of total trade is also converted into a line chart to reflect the trend, and the specific value for each year is indicated."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Applications homepage.\n\n\n\n\n\nIn this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "In-class_exercise/In-class_exercise_06.html",
    "href": "In-class_exercise/In-class_exercise_06.html",
    "title": "In-class_exercise_06",
    "section": "",
    "text": "Shiny link: https://xiehaoyangxhy.shinyapps.io/In-class_exercise_06/"
  },
  {
    "objectID": "In-class_exercise/In-class_exercise_04.html",
    "href": "In-class_exercise/In-class_exercise_04.html",
    "title": "In-class exercise 04",
    "section": "",
    "text": "Getting Started\nInstalling and loading R Packages\n\npacman:: p_load(tidyverse)\n\nImporting data into R environment\n\nexam_data &lt;- read.csv(\"data/Exam_data.csv\")\n\nPlotting\n\nggplot(data = exam_data,\n       aes(x = ENGLISH,\n           y = CLASS)) +\n  geom_boxplot()"
  },
  {
    "objectID": "In-class_exercise/In-class_exercise_02.html",
    "href": "In-class_exercise/In-class_exercise_02.html",
    "title": "In-class exercise 02",
    "section": "",
    "text": "Tableau Public link: https://public.tableau.com/app/profile/haoyang.xie/vizzes"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_07/Hands-on exercise 07.html",
    "href": "Hands-on_exercise/Hands-on_exercise_07/Hands-on exercise 07.html",
    "title": "Hands-on exercise 07",
    "section": "",
    "text": "pacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, CGPfunctions, ggHoriPlot, tidyverse)\n\n\n\n\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\n\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\n\n\n\n\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\n\nStep 1: Deriving attack by country object\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\n\nStep 1: Data Import\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\nStep 2: Deriving month and year fields\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\nStep 3: Extracting the target country\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\nStep 4: Computing year average arrivals by month\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\nStep 5: Plotting the cycle plot\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")\n\n\n\n\n\n\n\n\n\n\n\nStep 1: Data Import\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\nStep 2: Plotting the slopegraph\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_07/Hands-on exercise 07.html#getting-started",
    "href": "Hands-on_exercise/Hands-on_exercise_07/Hands-on exercise 07.html#getting-started",
    "title": "Hands-on exercise 07",
    "section": "",
    "text": "pacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, CGPfunctions, ggHoriPlot, tidyverse)\n\n\n\n\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\n\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_07/Hands-on exercise 07.html#data-preparation",
    "href": "Hands-on_exercise/Hands-on_exercise_07/Hands-on exercise 07.html#data-preparation",
    "title": "Hands-on exercise 07",
    "section": "",
    "text": "Step 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_07/Hands-on exercise 07.html#building-the-calendar-heatmaps",
    "href": "Hands-on_exercise/Hands-on_exercise_07/Hands-on exercise 07.html#building-the-calendar-heatmaps",
    "title": "Hands-on exercise 07",
    "section": "",
    "text": "grouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_07/Hands-on exercise 07.html#plotting-multiple-calendar-heatmaps",
    "href": "Hands-on_exercise/Hands-on_exercise_07/Hands-on exercise 07.html#plotting-multiple-calendar-heatmaps",
    "title": "Hands-on exercise 07",
    "section": "",
    "text": "Step 1: Deriving attack by country object\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_07/Hands-on exercise 07.html#plotting-cycle-plot",
    "href": "Hands-on_exercise/Hands-on_exercise_07/Hands-on exercise 07.html#plotting-cycle-plot",
    "title": "Hands-on exercise 07",
    "section": "",
    "text": "Step 1: Data Import\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\nStep 2: Deriving month and year fields\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\nStep 3: Extracting the target country\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\nStep 4: Computing year average arrivals by month\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\nStep 5: Plotting the cycle plot\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_07/Hands-on exercise 07.html#plotting-slopegraph",
    "href": "Hands-on_exercise/Hands-on_exercise_07/Hands-on exercise 07.html#plotting-slopegraph",
    "title": "Hands-on exercise 07",
    "section": "",
    "text": "Step 1: Data Import\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\nStep 2: Plotting the slopegraph\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-4.html",
    "href": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-4.html",
    "title": "Hands-on exercise 05-4: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "",
    "text": "pacman::p_load(GGally, parallelPlot, tidyverse)\n\n\n\n\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\n\n\n\n\n\n\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\n\n\n\n\n\n\n\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\n\n\n\n\n\n\n\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\n\n\n\n\n\n\n\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\n\n\n\n\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\n\n\n\n\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\n\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\n\n\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-4.html#getting-started",
    "href": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-4.html#getting-started",
    "title": "Hands-on exercise 05-4: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "",
    "text": "pacman::p_load(GGally, parallelPlot, tidyverse)\n\n\n\n\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-4.html#plotting-static-parallel-coordinates-plot",
    "href": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-4.html#plotting-static-parallel-coordinates-plot",
    "title": "Hands-on exercise 05-4: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "",
    "text": "ggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\n\n\n\n\n\n\n\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\n\n\n\n\n\n\n\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\n\n\n\n\n\n\n\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\n\n\n\n\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1))"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-4.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "href": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-4.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "title": "Hands-on exercise 05-4: Visual Multivariate Analysis with Parallel Coordinates Plot",
    "section": "",
    "text": "wh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\n\n\n\n\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\n\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\n\n\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-2.html",
    "href": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-2.html",
    "title": "Hands-on exercise 05-2: Visual Correlation Analysis",
    "section": "",
    "text": "pacman::p_load(corrplot, ggstatsplot, tidyverse)\n\n\n\n\n\nwine &lt;- read_csv(\"data/wine_quality.csv\")\n\n\n\n\n\n\n\n\npairs(wine[,1:11])\n\n\n\n\n\n\n\n\nThe required input of pairs() can be a matrix or data frame. The code chunk used to create the scatterplot matrix is relatively simple. It uses the default pairs function.\n\npairs(wine[,2:12])\n\n\n\n\n\n\n\n\n\n\n\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\n\n\n\n\nSimilarly, we can display the upper half of the correlation matrix by using the code chun below.\n\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\n\n\n\n\n\n\n\n\npanel.cor &lt;- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr &lt;- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr &lt;- abs(cor(x, y, use=\"complete.obs\"))\ntxt &lt;- format(c(r, 0.123456789), digits=digits)[1]\ntxt &lt;- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\n\n\n\n\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p &lt; 0.05\"\n)\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram. ggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot function. The list should avoid any of the following arguments since they are already internally being used: , , , , , , , , , .corrmethodp.matsig.levelggthemecolorslabpchlegend.titledigits The sample sub-code chunk can be used to control specific component of the plot such as the font size of the x-axis, y-axis, and the statistical report.\n\nggplot.component = list(\n    theme(text=element_text(size=5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8)))\n\n\n\n\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\nto build a facet plot, the only argument needed is .grouping.var Behind group_ggcorrmat(), patchwork package is used to create the multiplot. argument provides a list of additional arguments passed to patchwork::wrap_plots, except for guides argument which is already separately specified earlier.plotgrid.args Likewise, argument is calling plot annotation arguments of patchwork package.annotation.args\n\n\n\n\n\n\nBefore we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame.\nIn the code chunk below, cor() of R Stats is used to compute the correlation matrix of wine data frame.\n\nwine.cor &lt;- cor(wine[, 1:11])\n\nNext, corrplot() is used to plot the corrgram by using all the default setting as shown in the code chunk below.\n\ncorrplot(wine.cor)\n\n\n\n\n\n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\") \n\n\n\n\n\n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\")\n\n\n\n\n\n\n\n\nThe default layout of the corrgram can be further customised. For example, arguments diag and tl.col are used to turn off the diagonal cells and to change the axis text label colour to black colour respectively as shown in the code chunk and figure below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\n\n\n\n\n\n\n\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nThe code chunk used to plot the corrgram are shown below.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\n\n\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\nWe can then use the p.mat argument of corrplot function as shown in the code chunk below.\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\n\n\n\n\n\n\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-2.html#getting-started",
    "href": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-2.html#getting-started",
    "title": "Hands-on exercise 05-2: Visual Correlation Analysis",
    "section": "",
    "text": "pacman::p_load(corrplot, ggstatsplot, tidyverse)\n\n\n\n\n\nwine &lt;- read_csv(\"data/wine_quality.csv\")"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-2.html#building-correlation-matrix-pairs-method",
    "href": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-2.html#building-correlation-matrix-pairs-method",
    "title": "Hands-on exercise 05-2: Visual Correlation Analysis",
    "section": "",
    "text": "pairs(wine[,1:11])\n\n\n\n\n\n\n\n\nThe required input of pairs() can be a matrix or data frame. The code chunk used to create the scatterplot matrix is relatively simple. It uses the default pairs function.\n\npairs(wine[,2:12])\n\n\n\n\n\n\n\n\n\n\n\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\n\n\n\n\nSimilarly, we can display the upper half of the correlation matrix by using the code chun below.\n\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\n\n\n\n\n\n\n\n\npanel.cor &lt;- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr &lt;- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr &lt;- abs(cor(x, y, use=\"complete.obs\"))\ntxt &lt;- format(c(r, 0.123456789), digits=digits)[1]\ntxt &lt;- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-2.html#visualising-correlation-matrix-ggcormat",
    "href": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-2.html#visualising-correlation-matrix-ggcormat",
    "title": "Hands-on exercise 05-2: Visual Correlation Analysis",
    "section": "",
    "text": "ggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\n\n\n\n\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p &lt; 0.05\"\n)\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram. ggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot function. The list should avoid any of the following arguments since they are already internally being used: , , , , , , , , , .corrmethodp.matsig.levelggthemecolorslabpchlegend.titledigits The sample sub-code chunk can be used to control specific component of the plot such as the font size of the x-axis, y-axis, and the statistical report.\n\nggplot.component = list(\n    theme(text=element_text(size=5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8)))\n\n\n\n\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\nto build a facet plot, the only argument needed is .grouping.var Behind group_ggcorrmat(), patchwork package is used to create the multiplot. argument provides a list of additional arguments passed to patchwork::wrap_plots, except for guides argument which is already separately specified earlier.plotgrid.args Likewise, argument is calling plot annotation arguments of patchwork package.annotation.args"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-2.html#visualising-correlation-matrix-using-corrplot-package",
    "href": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-2.html#visualising-correlation-matrix-using-corrplot-package",
    "title": "Hands-on exercise 05-2: Visual Correlation Analysis",
    "section": "",
    "text": "Before we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame.\nIn the code chunk below, cor() of R Stats is used to compute the correlation matrix of wine data frame.\n\nwine.cor &lt;- cor(wine[, 1:11])\n\nNext, corrplot() is used to plot the corrgram by using all the default setting as shown in the code chunk below.\n\ncorrplot(wine.cor)\n\n\n\n\n\n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\") \n\n\n\n\n\n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\")\n\n\n\n\n\n\n\n\nThe default layout of the corrgram can be further customised. For example, arguments diag and tl.col are used to turn off the diagonal cells and to change the axis text label colour to black colour respectively as shown in the code chunk and figure below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\n\n\n\n\n\n\n\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nThe code chunk used to plot the corrgram are shown below.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\n\n\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\nWe can then use the p.mat argument of corrplot function as shown in the code chunk below.\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\n\n\n\n\n\n\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-4.html",
    "href": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-4.html",
    "title": "Hands-on exercise 04-4",
    "section": "",
    "text": "pacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\n\n\n\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)\n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  xrange = c(0, 6500),  #&lt;&lt;\n  yrange = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\n\n\n\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n\n\n\n\n\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-4.html#funnelplotr-methods-the-basic-plot",
    "href": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-4.html#funnelplotr-methods-the-basic-plot",
    "title": "Hands-on exercise 04-4",
    "section": "",
    "text": "funnel_plot(\n  .data = covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  xrange = c(0, 6500),  #&lt;&lt;\n  yrange = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion."
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-4.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-4.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on exercise 04-4",
    "section": "",
    "text": "To plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n\n\n\n\n\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-2.html",
    "href": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-2.html",
    "title": "Hands-on exercise 04-2: Visual Statistical Analysis",
    "section": "",
    "text": "pacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n\n\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npacman::p_load(readxl, performance, parameters, see)\n\n\n\n\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\n\n\n\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\n\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\n\n\n\n\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_n &lt;- check_normality(model1)\n\n\nplot(check_n)\n\n\n\n\n\n\n\n\n\n\n\n\ncheck_h &lt;- check_heteroscedasticity(model1)\n\n\nplot(check_h)\n\n\n\n\n\n\n\n\n\n\n\n\ncheck_model(model1)\n\n\n\n\n\n\n\n\n\n\n\n\nplot(parameters(model1))\n\n\n\n\n\n\n\n\n\n\n\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-2.html#getting-started",
    "href": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-2.html#getting-started",
    "title": "Hands-on exercise 04-2: Visual Statistical Analysis",
    "section": "",
    "text": "pacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n\n\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\n\n\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-2.html#getting-started-1",
    "href": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-2.html#getting-started-1",
    "title": "Hands-on exercise 04-2: Visual Statistical Analysis",
    "section": "",
    "text": "pacman::p_load(readxl, performance, parameters, see)\n\n\n\n\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\n\n\n\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\n\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\n\n\n\n\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_n &lt;- check_normality(model1)\n\n\nplot(check_n)\n\n\n\n\n\n\n\n\n\n\n\n\ncheck_h &lt;- check_heteroscedasticity(model1)\n\n\nplot(check_h)\n\n\n\n\n\n\n\n\n\n\n\n\ncheck_model(model1)\n\n\n\n\n\n\n\n\n\n\n\n\nplot(parameters(model1))\n\n\n\n\n\n\n\n\n\n\n\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_03/Hands-on_exercise_03-2.html",
    "href": "Hands-on_exercise/Hands-on_exercise_03/Hands-on_exercise_03-2.html",
    "title": "Hands-on exercise 03-2: Programming Animated Statistical Graphics with R",
    "section": "",
    "text": "Programming Animated Statistical Graphics with R\n\nLoading the R packages\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\n\nImporting the data\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\nBuilding a static population bubble plot\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\n\n\n\n\nBuilding the animated bubble plot\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')          \n\n\n\n\n\n\n\n\n\n\nBuilding an animated bubble plot: methodggplotly()\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)\n\n\n\n\n\n\nBuilding an animated bubble plot: methodplot_ly()\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_02/Hands-on_exercise_02.html",
    "href": "Hands-on_exercise/Hands-on_exercise_02/Hands-on_exercise_02.html",
    "title": "Hands-on exercise 02: Beyond ggplot2 Fundamentals",
    "section": "",
    "text": "pacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse) \n\n\n\n\n\nexam_data &lt;- read.csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_02/Hands-on_exercise_02.html#getting-started",
    "href": "Hands-on_exercise/Hands-on_exercise_02/Hands-on_exercise_02.html#getting-started",
    "title": "Hands-on exercise 02: Beyond ggplot2 Fundamentals",
    "section": "",
    "text": "pacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse) \n\n\n\n\n\nexam_data &lt;- read.csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_02/Hands-on_exercise_02.html#beyond-ggplot2-annotation-ggrepel",
    "href": "Hands-on_exercise/Hands-on_exercise_02/Hands-on_exercise_02.html#beyond-ggplot2-annotation-ggrepel",
    "title": "Hands-on exercise 02: Beyond ggplot2 Fundamentals",
    "section": "Beyond ggplot2 Annotation: ggrepel",
    "text": "Beyond ggplot2 Annotation: ggrepel\n\nGraph with annotation\n\nThe plotThe code\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\nWorking with ggrepel\n\nThe plotThe code\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\nBeyond ggplot2 Themes\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\n\nWorking with ggtheme package\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\n\n\nWorking with hrbthems package\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18,\n              base_size = 15,\n              grid = \"Y\")\n\n\n\n\n\n\nBeyond Single Graph\nP1\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\np2\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\np3\n\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\nCombining two ggplot2 graphs\n\np1 + p2\n\n\n\n\n\n\n\n\n\n\nCombining three ggplot2 graphs\n\n(p1 / p2) | p3\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nCreating figure with insert\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nCreating a composite figure by using patchwork and ggtheme\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_economist()\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_00/Hands-on_exercise_00.html",
    "href": "Hands-on_exercise/Hands-on_exercise_00/Hands-on_exercise_00.html",
    "title": "Hands-on exercise 00: working with tidyverse",
    "section": "",
    "text": "Load tidyverse onto r enviroment by using the code chunk below.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_00/Hands-on_exercise_00.html#getting-started",
    "href": "Hands-on_exercise/Hands-on_exercise_00/Hands-on_exercise_00.html#getting-started",
    "title": "Hands-on exercise 00: working with tidyverse",
    "section": "",
    "text": "Load tidyverse onto r enviroment by using the code chunk below.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_00/Hands-on_exercise_00.html#importing-data",
    "href": "Hands-on_exercise/Hands-on_exercise_00/Hands-on_exercise_00.html#importing-data",
    "title": "Hands-on exercise 00: working with tidyverse",
    "section": "Importing data",
    "text": "Importing data\nCode chunk below uses read.csv() of readr to import REALIS2019.csv into r environment as a tibble data.frame.\n\nrealis_csv &lt;- read.csv(\"data/REALIS2019.csv\")\n\n\nrealis2019 &lt;- read.csv(\"data/REALIS2019.csv\")\n\n\n#|eval: FALSE\npopdata_fat &lt;- read.csv(\"data/PopData2019_fat.csv\")"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_00/Hands-on_exercise_00.html#pivoting-data",
    "href": "Hands-on_exercise/Hands-on_exercise_00/Hands-on_exercise_00.html#pivoting-data",
    "title": "Hands-on exercise 00: working with tidyverse",
    "section": "Pivoting data",
    "text": "Pivoting data\n\n#|eval: FALSE\npopdata_long &lt;- popdata_fat %&gt;%\n  pivot_longer(c(3:21),\n               names_to = \"Age Group\",\n               values_to = \"Population\")\n\n\n#|eval: FALSE\nwrite_rds(popdata_long, \"rds/popdata_long.rds\")\n\n\n#|eval: FALSE\npopdata_long &lt;- read_rds(\"rds/popdata_long.rds\")"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_01/Hands-on_exercise_01.html",
    "href": "Hands-on_exercise/Hands-on_exercise_01/Hands-on_exercise_01.html",
    "title": "Hands-on exercise 01: ggplot2 methods",
    "section": "",
    "text": "pacman::p_load(tidyverse)\n\n\n\n\n\nexam_data &lt;- read.csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_01/Hands-on_exercise_01.html#getting-started",
    "href": "Hands-on_exercise/Hands-on_exercise_01/Hands-on_exercise_01.html#getting-started",
    "title": "Hands-on exercise 01: ggplot2 methods",
    "section": "",
    "text": "pacman::p_load(tidyverse)\n\n\n\n\n\nexam_data &lt;- read.csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_01/Hands-on_exercise_01.html#a-layered-grammar-of-graphics-ggplot2-methods",
    "href": "Hands-on_exercise/Hands-on_exercise_01/Hands-on_exercise_01.html#a-layered-grammar-of-graphics-ggplot2-methods",
    "title": "Hands-on exercise 01: ggplot2 methods",
    "section": "A Layered Grammar of Graphics: ggplot2 methods",
    "text": "A Layered Grammar of Graphics: ggplot2 methods\n\nPlotting a simple bar chart\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\nGeometric Objects: geom_dotplot\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)  \n\n\n\n\n\n\n\n\n\n\nGeometric Objects: geom_histogram()\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()       \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\nModifying a geometric object by changing geom()\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")  \n\n\n\n\n\n\n\n\n\n\nModifying a geometric object by changing aes()\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\n\n\n\n\n\nGeometric Objects: geom-density()\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()           \n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\nGeometric Objects: geom_boxplot\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()            \n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)\n\n\n\n\n\n\n\n\n\n\nGeometric Objects: geom_violin\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()\n\n\n\n\n\n\n\n\n\n\nGeometric Objects: geom_point()\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()            \n\n\n\n\n\n\n\n\n\n\ngeom objects can be combined\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)        \n\n\n\n\n\n\n\n\n\n\nWorking with stat - the stat_summary() method\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun=\"mean\",           \n             colour=\"red\",          \n             size=4)          \n\n\n\n\n\n\n\n\n\n\nAdding a best fit curve on a scatterplot\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nWorking with facet_wrap()\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\n\n\n\n\nfunctionfacet_grid()\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)\n\n\n\n\n\n\n\n\n\n\nWorking with Coordinate\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\nChanging the y- and x-axis range\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nWorking with theme\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_03/Hands-on_exercise_03-1.html",
    "href": "Hands-on_exercise/Hands-on_exercise_03/Hands-on_exercise_03-1.html",
    "title": "Hands-on exercise 03-1: Programming Interactive Data Visualisation with R",
    "section": "",
    "text": "pacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse) \n\n\n\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)                                        \n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter\n\n\nNo scatter mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -&gt; https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter\n\n\nNo scatter mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -&gt; https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\n\n\n\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\nSetting the `off` event (i.e., 'plotly_deselect') to match the `on` event (i.e., 'plotly_selected'). You can change this default via the `highlight()` function.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_03/Hands-on_exercise_03-1.html#getting-started",
    "href": "Hands-on_exercise/Hands-on_exercise_03/Hands-on_exercise_03-1.html#getting-started",
    "title": "Hands-on exercise 03-1: Programming Interactive Data Visualisation with R",
    "section": "",
    "text": "pacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse) \n\n\n\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_03/Hands-on_exercise_03-1.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_exercise/Hands-on_exercise_03/Hands-on_exercise_03-1.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on exercise 03-1: Programming Interactive Data Visualisation with R",
    "section": "",
    "text": "The plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)                                        \n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter\n\n\nNo scatter mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -&gt; https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -&gt; https://plotly.com/r/reference/#scatter\n\n\nNo scatter mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -&gt; https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\n\n\n\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\nSetting the `off` event (i.e., 'plotly_deselect') to match the `on` event (i.e., 'plotly_selected'). You can change this default via the `highlight()` function.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-1.html",
    "href": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-1.html",
    "title": "Hands-on exercise 04: Visualising Distribution",
    "section": "",
    "text": "pacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)\n\n\n\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-1.html#getting-started",
    "href": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-1.html#getting-started",
    "title": "Hands-on exercise 04: Visualising Distribution",
    "section": "",
    "text": "pacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse)\n\n\n\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-1.html#visualising-distribution-with-ridgeline-plot",
    "href": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-1.html#visualising-distribution-with-ridgeline-plot",
    "title": "Hands-on exercise 04: Visualising Distribution",
    "section": "",
    "text": "The plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-1.html#visualising-distribution-with-raincloud-plot",
    "href": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-1.html#visualising-distribution-with-raincloud-plot",
    "title": "Hands-on exercise 04: Visualising Distribution",
    "section": "",
    "text": "The plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-3.html",
    "href": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-3.html",
    "title": "Hands-on exercise 04-3: Visualising Uncertainty",
    "section": "",
    "text": "devtools::install_github(\"wilkelab/ungeviz\")\n\n\npacman::p_load(ungeviz, plotly, crosstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)\n\n\n\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\nCode chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\n\nThe tableThe code\n\n\n\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\nExample\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\n\n\n\nlibrary(ungeviz)\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-3.html#getting-started",
    "href": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-3.html#getting-started",
    "title": "Hands-on exercise 04-3: Visualising Uncertainty",
    "section": "",
    "text": "devtools::install_github(\"wilkelab/ungeviz\")\n\n\npacman::p_load(ungeviz, plotly, crosstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)\n\n\n\n\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-3.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-3.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands-on exercise 04-3: Visualising Uncertainty",
    "section": "",
    "text": "Code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\n\nThe tableThe code\n\n\n\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))\n\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\nExample\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-3.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "Hands-on_exercise/Hands-on_exercise_04/Hands-on exercise 04-3.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Hands-on exercise 04-3: Visualising Uncertainty",
    "section": "",
    "text": "devtools::install_github(\"wilkelab/ungeviz\")\n\n\n\n\n\nlibrary(ungeviz)\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-1.html",
    "href": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-1.html",
    "title": "Hands-on exercise 05-1: Creating Ternary Plot with R",
    "section": "",
    "text": "pacman::p_load(plotly, ggtern, tidyverse)\n\n\n\n\n\n\n\n\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\n\n\n\n\n#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)\n\n\n\n\n\n\n\n\n#Building the static ternary plot\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n#Building the static ternary plot\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\n\n\n\n\n\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-1.html#getting-started",
    "href": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-1.html#getting-started",
    "title": "Hands-on exercise 05-1: Creating Ternary Plot with R",
    "section": "",
    "text": "pacman::p_load(plotly, ggtern, tidyverse)"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-1.html#data-preparation",
    "href": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-1.html#data-preparation",
    "title": "Hands-on exercise 05-1: Creating Ternary Plot with R",
    "section": "",
    "text": "pop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\n\n\n\n\n#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-1.html#plotting-ternary-diagram-with-r",
    "href": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-1.html#plotting-ternary-diagram-with-r",
    "title": "Hands-on exercise 05-1: Creating Ternary Plot with R",
    "section": "",
    "text": "#Building the static ternary plot\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n#Building the static ternary plot\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\n\n\n\n\n\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-3.html",
    "href": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-3.html",
    "title": "Hands-on exercise 05-3: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "",
    "text": "pacman::p_load(seriation, dendextend, heatmaply, tidyverse)\n\n\n\n\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\n\n\n\n\nrow.names(wh) &lt;- wh$Country\n\nNotice that the row number has been replaced into the country name.\n\n\n\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)\n\nNotice that wh_matrix is in R matrix format.\n\n\n\n\n\n\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\n\n\n\n\nNote:\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\n\n\n\n\nNote:\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nheatmaply(mtcars)\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create n interactive heatmap by using heatmaply package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\nNote that:\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north.\n\n\n\n\n\n\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")\n\n\n\n\n\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)\n\n\n\n\n\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-3.html#getting-started",
    "href": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-3.html#getting-started",
    "title": "Hands-on exercise 05-3: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "",
    "text": "pacman::p_load(seriation, dendextend, heatmaply, tidyverse)\n\n\n\n\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\n\n\n\n\nrow.names(wh) &lt;- wh$Country\n\nNotice that the row number has been replaced into the country name.\n\n\n\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)\n\nNotice that wh_matrix is in R matrix format."
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-3.html#static-heatmap",
    "href": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-3.html#static-heatmap",
    "title": "Hands-on exercise 05-3: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "",
    "text": "wh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\n\n\n\n\nNote:\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\n\n\n\n\nNote:\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-3.html#creating-interactive-heatmap",
    "href": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-3.html#creating-interactive-heatmap",
    "title": "Hands-on exercise 05-3: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "",
    "text": "heatmaply(mtcars)\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create n interactive heatmap by using heatmaply package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\nNote that:\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north."
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-3.html#data-trasformation",
    "href": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-3.html#data-trasformation",
    "title": "Hands-on exercise 05-3: Heatmap for Visualising and Analysing Multivariate Data",
    "section": "",
    "text": "heatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")\n\n\n\n\n\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)\n\n\n\n\n\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-5.html",
    "href": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-5.html",
    "title": "Hands-on exercise 05-5: Treemap Visualisation with R",
    "section": "",
    "text": "pacman::p_load(treemap, treemapify, tidyverse) \n\n\n\n\n\n\n\n\nrealis2018 &lt;- read_csv(\"data/realis2018.csv\")\n\n\n\n\nThe data.frame realis2018 is in trasaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. In this section, we will perform the following steps to manipulate and prepare a data.frtame that is appropriate for treemap visualisation:\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale, and compute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($) respectively. Two key verbs of dplyr package, namely: group_by() and summarize() will be used to perform these steps.\ngroup_by() breaks down a data.frame into specified groups of rows. When you then apply the verbs above on the resulting object they’ll be automatically applied “by group”.\nGrouping affects the verbs as follows:\ngrouped select() is the same as ungrouped select(), except that grouping variables are always retained. grouped arrange() is the same as ungrouped; unless you set .by_group = TRUE, in which case it orders first by the grouping variables. mutate() and filter() are most useful in conjunction with window functions (like rank(), or min(x) == x). They are described in detail in vignette(“window-functions”). sample_n() and sample_frac() sample the specified number/fraction of rows in each group. summarise() computes the summary for each group. In our case, group_by() will used together with summarise() to derive the summarised data.frame.\n\n\n\n\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\nThe code chunk above is not very efficient because we have to give each intermediate data.frame a name, even though we don’t have to care about it.\n\n\n\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\n\n\n\ntreemap package is a R package specially designed to offer great flexibility in drawing treemaps. The core function, namely: treemap() offers at least 43 arguments. In this section, we will only explore the major arguments for designing elegent and yet truthful treemaps.\n\n\n\nrealis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\n\n\n\nThe code chunk below designed a treemap by using three core arguments of treemap(), namely: index, vSize and vColor.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, type argument is define as value.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below shows a value type treemap.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nThe “manual” type does not interpret the values as the “value” type does. Instead, the value range is mapped linearly to the colour palette.\nThe code chunk below shows a manual type treemap.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\nThe colour scheme used is very copnfusing. This is because mapping = (min(values), mean(range(values)), max(values)). It is not wise to use diverging colour palette such as RdYlBu if the values are all positive or negative To overcome this problem, a single colour palette such as Blues should be used.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below plots a squarified treemap by changing the algorithm argument.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nWhen “pivotSize” algorithm is used, sortID argument can be used to dertemine the order in which the rectangles are placed from top left to bottom right.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")\n\n\n\n\n\n\n\n\n\n\n\nGroup by Planning Region\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap()\n\n\n\n\n\n\n\n\nGroup by Planning Area\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap()\n\n\n\n\n\n\n\n\nAdding boundary line\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"gray40\",\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\")"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-5.html#getting-started",
    "href": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-5.html#getting-started",
    "title": "Hands-on exercise 05-5: Treemap Visualisation with R",
    "section": "",
    "text": "pacman::p_load(treemap, treemapify, tidyverse)"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-5.html#data-wrangling",
    "href": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-5.html#data-wrangling",
    "title": "Hands-on exercise 05-5: Treemap Visualisation with R",
    "section": "",
    "text": "realis2018 &lt;- read_csv(\"data/realis2018.csv\")\n\n\n\n\nThe data.frame realis2018 is in trasaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. In this section, we will perform the following steps to manipulate and prepare a data.frtame that is appropriate for treemap visualisation:\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale, and compute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($) respectively. Two key verbs of dplyr package, namely: group_by() and summarize() will be used to perform these steps.\ngroup_by() breaks down a data.frame into specified groups of rows. When you then apply the verbs above on the resulting object they’ll be automatically applied “by group”.\nGrouping affects the verbs as follows:\ngrouped select() is the same as ungrouped select(), except that grouping variables are always retained. grouped arrange() is the same as ungrouped; unless you set .by_group = TRUE, in which case it orders first by the grouping variables. mutate() and filter() are most useful in conjunction with window functions (like rank(), or min(x) == x). They are described in detail in vignette(“window-functions”). sample_n() and sample_frac() sample the specified number/fraction of rows in each group. summarise() computes the summary for each group. In our case, group_by() will used together with summarise() to derive the summarised data.frame.\n\n\n\n\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\nThe code chunk above is not very efficient because we have to give each intermediate data.frame a name, even though we don’t have to care about it.\n\n\n\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-5.html#designing-treemap-with-treemap-package",
    "href": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-5.html#designing-treemap-with-treemap-package",
    "title": "Hands-on exercise 05-5: Treemap Visualisation with R",
    "section": "",
    "text": "treemap package is a R package specially designed to offer great flexibility in drawing treemaps. The core function, namely: treemap() offers at least 43 arguments. In this section, we will only explore the major arguments for designing elegent and yet truthful treemaps.\n\n\n\nrealis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\n\n\n\nThe code chunk below designed a treemap by using three core arguments of treemap(), namely: index, vSize and vColor.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, type argument is define as value.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below shows a value type treemap.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nThe “manual” type does not interpret the values as the “value” type does. Instead, the value range is mapped linearly to the colour palette.\nThe code chunk below shows a manual type treemap.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\nThe colour scheme used is very copnfusing. This is because mapping = (min(values), mean(range(values)), max(values)). It is not wise to use diverging colour palette such as RdYlBu if the values are all positive or negative To overcome this problem, a single colour palette such as Blues should be used.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below plots a squarified treemap by changing the algorithm argument.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\nWhen “pivotSize” algorithm is used, sortID argument can be used to dertemine the order in which the rectangles are placed from top left to bottom right.\n\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-5.html#designing-treemap-using-treemapify-package",
    "href": "Hands-on_exercise/Hands-on_exercise_05/Hands-on exercise 05-5.html#designing-treemap-using-treemapify-package",
    "title": "Hands-on exercise 05-5: Treemap Visualisation with R",
    "section": "",
    "text": "ggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")\n\n\n\n\n\n\n\n\n\n\n\nGroup by Planning Region\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap()\n\n\n\n\n\n\n\n\nGroup by Planning Area\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap()\n\n\n\n\n\n\n\n\nAdding boundary line\n\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"gray40\",\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\")"
  },
  {
    "objectID": "In-class_exercise/In-class_exercise_01.html",
    "href": "In-class_exercise/In-class_exercise_01.html",
    "title": "In-class exercise 01",
    "section": "",
    "text": "Tableau Public link: https://public.tableau.com/app/profile/haoyang.xie/vizzes"
  },
  {
    "objectID": "In-class_exercise/In-class_exercise_03.html",
    "href": "In-class_exercise/In-class_exercise_03.html",
    "title": "In-class exercise 03",
    "section": "",
    "text": "Tableau Public link: https://public.tableau.com/app/profile/haoyang.xie/vizzes"
  },
  {
    "objectID": "In-class_exercise/In-class_exercise_05.html",
    "href": "In-class_exercise/In-class_exercise_05.html",
    "title": "In-class exercise 05",
    "section": "",
    "text": "Getting Started\n\npacman::p_load(tidyverse, readxl, SmartEDA, easystats, gtsummary)\n\nImporting Data\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\",\"data\")\n\n\nsummary(car_resale)\n\n       Id            Model               Price         Age_08_04    \n Min.   :   1.0   Length:1436        Min.   : 4350   Min.   : 1.00  \n 1st Qu.: 361.8   Class :character   1st Qu.: 8450   1st Qu.:44.00  \n Median : 721.5   Mode  :character   Median : 9900   Median :61.00  \n Mean   : 721.6                      Mean   :10731   Mean   :55.95  \n 3rd Qu.:1081.2                      3rd Qu.:11950   3rd Qu.:70.00  \n Max.   :1442.0                      Max.   :32500   Max.   :80.00  \n   Mfg_Month         Mfg_Year          KM         Quarterly_Tax   \n Min.   : 1.000   Min.   :1998   Min.   :     1   Min.   : 19.00  \n 1st Qu.: 3.000   1st Qu.:1998   1st Qu.: 43000   1st Qu.: 69.00  \n Median : 5.000   Median :1999   Median : 63390   Median : 85.00  \n Mean   : 5.549   Mean   :2000   Mean   : 68533   Mean   : 87.12  \n 3rd Qu.: 8.000   3rd Qu.:2001   3rd Qu.: 87021   3rd Qu.: 85.00  \n Max.   :12.000   Max.   :2004   Max.   :243000   Max.   :283.00  \n     Weight     Guarantee_Period    HP_Bin             CC_bin         \n Min.   :1000   Min.   : 3.000   Length:1436        Length:1436       \n 1st Qu.:1040   1st Qu.: 3.000   Class :character   Class :character  \n Median :1070   Median : 3.000   Mode  :character   Mode  :character  \n Mean   :1072   Mean   : 3.815                                        \n 3rd Qu.:1085   3rd Qu.: 3.000                                        \n Max.   :1615   Max.   :36.000                                        \n     Doors           Gears         Cylinders  Fuel_Type        \n Min.   :2.000   Min.   :3.000   Min.   :4   Length:1436       \n 1st Qu.:3.000   1st Qu.:5.000   1st Qu.:4   Class :character  \n Median :4.000   Median :5.000   Median :4   Mode  :character  \n Mean   :4.033   Mean   :5.026   Mean   :4                     \n 3rd Qu.:5.000   3rd Qu.:5.000   3rd Qu.:4                     \n Max.   :5.000   Max.   :6.000   Max.   :4                     \n    Color             Met_Color        Automatic       Mfr_Guarantee   \n Length:1436        Min.   :0.0000   Min.   :0.00000   Min.   :0.0000  \n Class :character   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000  \n Mode  :character   Median :1.0000   Median :0.00000   Median :0.0000  \n                    Mean   :0.6748   Mean   :0.05571   Mean   :0.4095  \n                    3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:1.0000  \n                    Max.   :1.0000   Max.   :1.00000   Max.   :1.0000  \n BOVAG_Guarantee       ABS            Airbag_1         Airbag_2     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:1.0000   1st Qu.:1.0000   1st Qu.:1.0000   1st Qu.:0.0000  \n Median :1.0000   Median :1.0000   Median :1.0000   Median :1.0000  \n Mean   :0.8955   Mean   :0.8134   Mean   :0.9708   Mean   :0.7228  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n     Airco        Automatic_airco   Boardcomputer      CD_Player     \n Min.   :0.0000   Min.   :0.00000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :1.0000   Median :0.00000   Median :0.0000   Median :0.0000  \n Mean   :0.5084   Mean   :0.05641   Mean   :0.2946   Mean   :0.2187  \n 3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:1.0000   3rd Qu.:0.0000  \n Max.   :1.0000   Max.   :1.00000   Max.   :1.0000   Max.   :1.0000  \n  Central_Lock    Powered_Windows Power_Steering       Radio       \n Min.   :0.0000   Min.   :0.000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:1.0000   1st Qu.:0.0000  \n Median :1.0000   Median :1.000   Median :1.0000   Median :0.0000  \n Mean   :0.5801   Mean   :0.562   Mean   :0.9777   Mean   :0.1462  \n 3rd Qu.:1.0000   3rd Qu.:1.000   3rd Qu.:1.0000   3rd Qu.:0.0000  \n Max.   :1.0000   Max.   :1.000   Max.   :1.0000   Max.   :1.0000  \n   Mistlamps      Sport_Model     Backseat_Divider  Metallic_Rim   \n Min.   :0.000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:1.0000   1st Qu.:0.0000  \n Median :0.000   Median :0.0000   Median :1.0000   Median :0.0000  \n Mean   :0.257   Mean   :0.3001   Mean   :0.7702   Mean   :0.2047  \n 3rd Qu.:1.000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000  \n Max.   :1.000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n Radio_cassette      Tow_Bar      \n Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000  \n Mean   :0.1455   Mean   :0.2779  \n 3rd Qu.:0.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000  \n\n\n\nlist(car_resale)\n\n[[1]]\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\nData Overview\n\ncar_resale %&gt;%\n  ExpData(type = 2)\n\n   Index    Variable_Name Variable_Type Sample_n Missing_Count Per_of_Missing\n1      1               Id       numeric     1436             0              0\n2      2            Model     character     1436             0              0\n3      3            Price       numeric     1436             0              0\n4      4        Age_08_04       numeric     1436             0              0\n5      5        Mfg_Month       numeric     1436             0              0\n6      6         Mfg_Year       numeric     1436             0              0\n7      7               KM       numeric     1436             0              0\n8      8    Quarterly_Tax       numeric     1436             0              0\n9      9           Weight       numeric     1436             0              0\n10    10 Guarantee_Period       numeric     1436             0              0\n11    11           HP_Bin     character     1436             0              0\n12    12           CC_bin     character     1436             0              0\n13    13            Doors       numeric     1436             0              0\n14    14            Gears       numeric     1436             0              0\n15    15        Cylinders       numeric     1436             0              0\n16    16        Fuel_Type     character     1436             0              0\n17    17            Color     character     1436             0              0\n18    18        Met_Color       numeric     1436             0              0\n19    19        Automatic       numeric     1436             0              0\n20    20    Mfr_Guarantee       numeric     1436             0              0\n21    21  BOVAG_Guarantee       numeric     1436             0              0\n22    22              ABS       numeric     1436             0              0\n23    23         Airbag_1       numeric     1436             0              0\n24    24         Airbag_2       numeric     1436             0              0\n25    25            Airco       numeric     1436             0              0\n26    26  Automatic_airco       numeric     1436             0              0\n27    27    Boardcomputer       numeric     1436             0              0\n28    28        CD_Player       numeric     1436             0              0\n29    29     Central_Lock       numeric     1436             0              0\n30    30  Powered_Windows       numeric     1436             0              0\n31    31   Power_Steering       numeric     1436             0              0\n32    32            Radio       numeric     1436             0              0\n33    33        Mistlamps       numeric     1436             0              0\n34    34      Sport_Model       numeric     1436             0              0\n35    35 Backseat_Divider       numeric     1436             0              0\n36    36     Metallic_Rim       numeric     1436             0              0\n37    37   Radio_cassette       numeric     1436             0              0\n38    38          Tow_Bar       numeric     1436             0              0\n   No_of_distinct_values\n1                   1436\n2                    372\n3                    236\n4                     77\n5                     12\n6                      7\n7                   1263\n8                     13\n9                     59\n10                     9\n11                     3\n12                     3\n13                     4\n14                     4\n15                     1\n16                     3\n17                    10\n18                     2\n19                     2\n20                     2\n21                     2\n22                     2\n23                     2\n24                     2\n25                     2\n26                     2\n27                     2\n28                     2\n29                     2\n30                     2\n31                     2\n32                     2\n33                     2\n34                     2\n35                     2\n36                     2\n37                     2\n38                     2\n\n\n\ncols &lt;- c(\"Mfg_Month\", \"HP_Bin\", \"CC_bin\", \"Doors\", \"Gears\", \"Cylinders\", \"Fuel_Type\", \"Color\", \"ABS\", \"Airbag_1\",\n          \"Met_Color\", \"Automatic\", \"Mfr_Guarantee\", \"BOVAG_Guarantee\", \"CD_Player\", \"Airbag_2\", \"Airco\", \"Automatic_airco\", \n          \"Boardcomputer\", \"Mistlamps\", \"Central_Lock\", \"Powered_Windows\", \"Power_Steering\", \"Radio\",\n          \"Sport_Model\", \"Backseat_Divider\", \"Metallic_Rim\", \"Radio_cassette\", \"Tow_Bar\")\n\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\",\n                       sheet = \"data\") %&gt;%\n  mutate(Id = as.character(Id)) %&gt;%\n  mutate_each_(funs(factor(.)),cols)\n\n\ncar_resale %&gt;%\n  ExpNumViz(target = NULL,\n            nlim = 10,\n            Page = c(2,2))\n\n$`0`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncar_resale %&gt;%\n  ExpNumViz(target = \"Price\",\n            nlim = 10,\n            Page = c(2,2))\n\n$`0`\n\n\n\n\n\n\n\n\n\n\ncar_resale %&gt;%\n  ExpCatViz(target = NULL,\n            col = \"sky blue\",\n            clim = 10,\n            margin = 2,\n            Page = c(4,4),\n            sample = 16)\n\n$`0`\n\n\n\n\n\n\n\n\n\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM +\n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\n\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n               Weight + Guarantee_Period, data = car_resale)\ncheck_normality(model1)\n\nWarning: Non-normality of residuals detected (p &lt; .001).\n\n\n\ncheck_heteroscedasticity(model1)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\n\n\ncheck_model(model1)\n\n\n\n\n\n\n\n\n\nsummary(model1)\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10249.4   -768.6    -15.4    738.5   6356.5 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      -2.186e+03  9.722e+02  -2.248   0.0247 *  \nAge_08_04        -1.195e+02  2.760e+00 -43.292   &lt;2e-16 ***\nKM               -2.406e-02  1.201e-03 -20.042   &lt;2e-16 ***\nWeight            1.972e+01  8.379e-01  23.533   &lt;2e-16 ***\nGuarantee_Period  2.682e+01  1.261e+01   2.126   0.0336 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1413 on 1431 degrees of freedom\nMultiple R-squared:  0.8486,    Adjusted R-squared:  0.8482 \nF-statistic:  2005 on 4 and 1431 DF,  p-value: &lt; 2.2e-16\n\n\n\np_model &lt;- parameters(model1)\n\n\nplot(parameters(model1))\n\n\n\n\n\n\n\n\n\nlibrary(ggstatsplot)\nggcoefstats(model1,\n             output = \"plot\")"
  },
  {
    "objectID": "In-class_exercise/In-class_exercise_07.html",
    "href": "In-class_exercise/In-class_exercise_07.html",
    "title": "In-class_exercise_07",
    "section": "",
    "text": "Getting started\n\npacman::p_load(tidyverse, tsibble, feasts, fable, seasonal)\n\nImporting data\n\nts_data &lt;- read_csv(\"data/visitor_arrivals_by_air.csv\")\n\nRows: 144 Columns: 34\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): Month-Year\ndbl (33): Republic of South Africa, Canada, USA, Bangladesh, Brunei, China, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nts_data$`Month-Year` &lt;- dmy(\n  ts_data$`Month-Year`)\n\nConventional base ‘ts’ object versus ‘tibble’ object\n\nts_data_ts &lt;- ts(ts_data)\nhead(ts_data_ts)\n\n     Month-Year Republic of South Africa Canada   USA Bangladesh Brunei China\n[1,]      13879                     3680   6972 31155       6786   3729 79599\n[2,]      13910                     1662   6056 27738       6314   3070 82074\n[3,]      13939                     3394   6220 31349       7502   4805 72546\n[4,]      13970                     3337   4764 26376       7333   3096 76112\n[5,]      14000                     2089   4460 26788       7988   3586 64808\n[6,]      14031                     2515   3888 29725       8301   5284 55238\n     Hong Kong SAR (China) India Indonesia Japan South Korea Kuwait Malaysia\n[1,]                 17103 41639     62683 37673       27937    284    31352\n[2,]                 21089 37170     47834 35297       22633    241    35030\n[3,]                 23230 44815     64688 42575       22876    206    37629\n[4,]                 17688 49527     58074 26839       20634    193    37521\n[5,]                 19340 67754     57089 30814       22785    140    38044\n[6,]                 19152 57380     70118 31001       22575    354    40419\n     Myanmar Pakistan Philippines Saudi Arabia Sri Lanka Taiwan Thailand\n[1,]    5269     1395       18622          406      5289  13757    18370\n[2,]    4643     1027       21609          591      4767  13921    16400\n[3,]    6218     1635       28464          626      4988  11181    23387\n[4,]    7324     1232       30131          644      7639  11665    24469\n[5,]    5395     1306       30193          470      5125  11436    21935\n[6,]    5542     1996       25800          772      4791  10689    19900\n     United Arab Emirates Vietnam Belgium & Luxembourg Finland France Germany\n[1,]                 2652   10315                 1341    1179   6918   11982\n[2,]                 2230   13415                 1449    1207   7876   13256\n[3,]                 3353   14320                 1674    1071   8066   15185\n[4,]                 3245   15413                 1426     768   8312   11604\n[5,]                 2856   14424                 1243     690   7066    9853\n[6,]                 4292   21368                 1255     624   5926    9347\n     Italy Netherlands Spain Switzerland United Kingdom Australia New Zealand\n[1,]  2953        4938  1668        4450          41934     71260        7806\n[2,]  2704        4885  1568        4381          44029     45595        4729\n[3,]  2822        5015  2254        5015          49489     53191        6106\n[4,]  3018        4902  1503        5434          35771     56514        7560\n[5,]  2165        4397  1365        4427          24464     57808        9090\n[6,]  2022        4166  1446        3359          22473     63350        9681\n\n\n\nts_tsibble &lt;- ts_data %&gt;%\n  mutate(Month = yearmonth(`Month-Year`)) %&gt;%\n  as_tsibble(index = `Month`)\n\n\nts_longer &lt;- ts_data %&gt;%\n  pivot_longer(cols = c(2:34),\n               names_to = \"Country\",\n               values_to = \"Arrivals\")\n\n\nts_longer %&gt;%\n  filter(Country == \"Vietnam\") %&gt;%\n  ggplot(aes(x = `Month-Year`, \n             y = Arrivals))+\n  geom_line(size = 0.5)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\nggplot(data = ts_longer, \n       aes(x = `Month-Year`, \n           y = Arrivals,\n           color = Country))+\n  geom_line(size = 0.5) +\n  theme(legend.position = \"bottom\", \n        legend.box.spacing = unit(0.5, \"cm\"))\n\n\n\n\n\n\n\n\n\nggplot(data = ts_longer, \n       aes(x = `Month-Year`, \n           y = Arrivals))+\n  geom_line(size = 0.5) +\n  facet_wrap(~ Country,\n             ncol = 3,\n             scales = \"free_y\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\ntsibble_longer &lt;- ts_tsibble %&gt;%\n  pivot_longer(cols = c(2:34),\n               names_to = \"Country\",\n               values_to = \"Arrivals\")\n\n\ntsibble_longer %&gt;%\n  filter(Country == \"Italy\" |\n         Country == \"Vietnam\" |\n         Country == \"United Kingdom\" |\n         Country == \"Germany\") %&gt;% \n  gg_season(Arrivals)\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(Country == \"Vietnam\" |\n         Country == \"Italy\") %&gt;% \n  autoplot(Arrivals) + \n  facet_grid(Country ~ ., scales = \"free_y\")\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(Country == \"Vietnam\" |\n         Country == \"Italy\") %&gt;% \n  gg_subseries(Arrivals)\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  ACF(Arrivals) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  PACF(Arrivals) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\" |\n         `Country` == \"Italy\" |\n         `Country` == \"United Kingdom\" |\n         `Country` == \"China\") %&gt;%\n  ACF(Arrivals) %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\" |\n         `Country` == \"Italy\" |\n         `Country` == \"United Kingdom\" |\n         `Country` == \"China\") %&gt;%\n  PACF(Arrivals) %&gt;%\n  autoplot()\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  gg_tsdisplay(Arrivals)\n\n\n\n\n\n\n\n\n\ntsibble_longer %&gt;%\n  filter(`Country` == \"Vietnam\") %&gt;%\n  model(stl = STL(Arrivals)) %&gt;%\n  components() %&gt;%\n  autoplot()"
  },
  {
    "objectID": "Take-home_exercise/Take-home_exercise_1.html",
    "href": "Take-home_exercise/Take-home_exercise_1.html",
    "title": "Take-home exercise 1",
    "section": "",
    "text": "With the rising prevalence of cardiovascular diseases worldwide, public attention to these conditions has also increased. Therefore, using data to identify risk factors for heart disease is crucial. This dataset focuses on Japanese citizens, recording their health status, risk factors, and personal conditions to explore potential insights within the data.\n\n\n\nThis take-home exercise aims to apply appropriate Exploratory Data Analysis (EDA) methods and ggplot2 functions to analyze the data. Based on the analysis and observations, it also briefly suggests potential insights for future research to help policymakers improve public healthcare.\n\n\n\n\n\n\n\n\n\n\n\n\n\nPackage\nfunction\n\n\n\n\nggplot2\nFor data visualization, creating high-quality charts.\n\n\ndplyr\nFor data manipulation, providing efficient filtering, transformation, and summarization functions.\n\n\nscales\nFor adjusting scales, axes, and formatting in ggplot2 charts.\n\n\ntidyverse\nA collection of data science packages, for data processing and visualization.\n\n\nggridges\nFor creating ridge plots, useful for visualizing density distributions.\n\n\ncolorspace\nFor advanced color management, including color transformations and palette selection.\n\n\nplotly\nFor creating interactive charts, including 3D and dynamic visualizations.\n\n\ncrosstalk\nFor enabling interactive data sharing between different HTML widgets (e.g., plotly, DT tables).\n\n\nDT\nFor creating interactive HTML data tables.\n\n\nggdist\nFor statistical visualizations, such as distributions and uncertainty representations.\n\n\ngganimate\nFor animating ggplot2 charts, enabling time-series or dynamic visualizations.\n\n\n\n\npacman::p_load(ggplot2, dplyr, scales, tidyverse, ggridges, colorspace, plotly, crosstalk, DT, ggdist, gganimate) \n\n\n\n\nThe dataset comes from Kaggle, with 1 table, 32 columns, and 30,000 rows. Each row of data represents the basic physical condition of a Japanese citizen.\n\n\n\n\nheart_attack_data &lt;- read.csv(\"data/japan_heart_attack_dataset.csv\")\n\n\n\n\nCheck the data set for duplicate data to prevent interference with subsequent analysis.\n\nheart_attack_data[duplicated(heart_attack_data), ]\n\n [1] Age                     Gender                  Region                 \n [4] Smoking_History         Diabetes_History        Hypertension_History   \n [7] Cholesterol_Level       Physical_Activity       Diet_Quality           \n[10] Alcohol_Consumption     Stress_Levels           BMI                    \n[13] Heart_Rate              Systolic_BP             Diastolic_BP           \n[16] Family_History          Heart_Attack_Occurrence Extra_Column_1         \n[19] Extra_Column_2          Extra_Column_3          Extra_Column_4         \n[22] Extra_Column_5          Extra_Column_6          Extra_Column_7         \n[25] Extra_Column_8          Extra_Column_9          Extra_Column_10        \n[28] Extra_Column_11         Extra_Column_12         Extra_Column_13        \n[31] Extra_Column_14         Extra_Column_15        \n&lt;0 rows&gt; (or 0-length row.names)\n\n\nThe result shows no duplicate data.\n\n\n\nAccording to Fabian Sanchis-Gomar. (2016). Epidemiology of coronary heart disease and acute coronary syndrome. This analysis will focus on the following factors:\n\n\n\n\n\n\n\n\n\nNo\nName\nDescription\nType of Variable\n\n\n\n\n1\nAge\nAge of respondents\nNumerical\n\n\n2\nGender\nMale or Female\nCategorical\n\n\n3\nSmoking History\nYes or No\nCategorical\n\n\n4\nDiabetes History\nYes or No\nCategorical\n\n\n5\nPhysical Activity\nIntensity level of physical activity\nNumerical\n\n\n6\nCholesterol_Level\nCholesterol levels of respondents\nNumerical\n\n\n7\nStress Level\nStress Level of respondents\nNumerical\n\n\n8\nBMI\nWeight / Height ², used to determine the weight health status of respondents\nNumerical\n\n\n9\nFamily History\nYes or No\nCategorical\n\n\n10\nHeart Attack Occurrence\nYes or No\nCategorical\n\n\n\nTherefore, only relevant columns are selected for analysis.\n\nselect_data &lt;- heart_attack_data %&gt;% select (Age, Gender, Smoking_History, Diabetes_History, Physical_Activity, Cholesterol_Level, Stress_Levels, BMI, Family_History, Heart_Attack_Occurrence )\n\nUse the code to perform checks on the newly generated dataset.\n\nglimpse(select_data)\n\nRows: 30,000\nColumns: 10\n$ Age                     &lt;int&gt; 56, 69, 46, 32, 60, 25, 78, 38, 56, 75, 36, 40…\n$ Gender                  &lt;chr&gt; \"Male\", \"Male\", \"Male\", \"Female\", \"Female\", \"F…\n$ Smoking_History         &lt;chr&gt; \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"Y…\n$ Diabetes_History        &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No…\n$ Physical_Activity       &lt;chr&gt; \"Moderate\", \"Low\", \"Low\", \"Moderate\", \"High\", …\n$ Cholesterol_Level       &lt;dbl&gt; 186.4002, 185.1367, 210.6966, 211.1655, 223.81…\n$ Stress_Levels           &lt;dbl&gt; 3.644786, 3.384056, 3.810911, 6.014878, 6.8068…\n$ BMI                     &lt;dbl&gt; 33.96135, 28.24287, 27.60121, 23.71729, 19.771…\n$ Family_History          &lt;chr&gt; \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ Heart_Attack_Occurrence &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n\n\n\n\n\n\nany(is.na(select_data))\n\n[1] FALSE\n\n\nThe result shows no missing values.\n\n\n\n\n\n\nSince the number of respondents in each age group is not necessarily the same (i.e., the age distribution is not necessarily balanced), it is also necessary to consider the age distribution of the respondents.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(select_data, aes(x = Age)) +\n  geom_histogram(data = select_data, aes(x = Age), binwidth = 5, fill = \"lightgray\", color = \"black\", alpha = 0.5) +\n  geom_histogram(data = subset(select_data, Heart_Attack_Occurrence == \"Yes\"), aes(x = Age), binwidth = 5, fill = \"tomato\", color = \"black\", alpha = 0.7) +\n  labs(x = \"Age\", y = \"Count\", title = \"Age Distribution for All People and Heart Attack Patients\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nInsight 1\n\n\n\n\nAs we can see from the graph above, there is no significant relationship between whether or not a person has heart disease and their age in Japan. The distribution of the number of people with heart disease does not change significantly with age, and the number of people with heart disease is basically the same as the age distribution of the respondents.\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(scales)\ndata_summary &lt;- select_data %&gt;%\n  group_by(Heart_Attack_Occurrence, Gender) %&gt;%\n  summarise(count = n()) %&gt;%\n  ungroup() %&gt;%\n  mutate(total_count = sum(count), percentage = count / total_count)\n\nggplot(data_summary, aes(x = \"\", y = count, fill = interaction(Heart_Attack_Occurrence, Gender))) +\n  geom_bar(stat = \"identity\", width = 1, color = \"white\") +\n  coord_polar(theta = \"y\") +  \n  labs(title = \"Heart Attack Occurrence vs Gender\", fill = \"Heart Attack Occurrence and Gender\") +\n  theme_void() +  \n  scale_fill_manual(values = c(\"lightcoral\", \"salmon\", \"lightsteelblue\", \"skyblue\")) +\n  geom_text(aes(label = percent(percentage)), position = position_stack(vjust = 0.5), color = \"black\")\n\n\n\n\n\n\n\n\n\n\nInsight 2\n\n\n\n\nFrom the above figure, we can see that the proportion of men and women with heart disease is almost the same when the ratio of men and women respondents is almost the same, so it can be seen that whether or not to suffer from heart disease has nothing to do with the gender of the patients in Japan.\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndf_prop &lt;- select_data %&gt;%\n  pivot_longer(cols = c(Diabetes_History, Smoking_History, Family_History),\n               names_to = \"Risk_Factor\",\n               values_to = \"Status\") %&gt;%\n  group_by(Risk_Factor, Status) %&gt;%\n  summarise(Heart_Attack_Rate = mean(Heart_Attack_Occurrence == \"Yes\")) %&gt;%\n  ungroup()\n\nggplot(df_prop, aes(x = Status, y = Heart_Attack_Rate, fill = Status)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  facet_wrap(~ Risk_Factor) +\n  theme_minimal() +\n  labs(title = \"Heart Attack Occurrence by Risk Factors\",\n       x = \"Risk Factor Status (Yes/No)\",\n       y = \"Heart Attack Occurrence Rate\",\n       fill = \"Risk Factor Status\") +\n  scale_y_continuous(labels = scales::percent) +  # Convert Y-axis to percentage\n  scale_fill_manual(values = c(\"No\" = \"skyblue\", \"Yes\" = \"lightcoral\"))\n\n\n\n\n\n\n\n\n\n\nInsight 3\n\n\n\n\nAs we can see from the graph above, people with diabetes and a history of smoking are a bit more likely to get heart disease than the general population in Japan, but the overall percentage difference is not significant..\n\n\n\n\n\n\nBecause the number of people at different exercise intensities is itself different, the ratio of their numbers will also be considered.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(select_data, aes(x = Physical_Activity)) +\n  geom_bar(data = select_data, aes(x = Physical_Activity), binwidth = 5, fill = \"lightgray\", color = \"black\", alpha = 0.5) +\n  geom_bar(data = subset(select_data, Heart_Attack_Occurrence == \"Yes\"), aes(x = Physical_Activity), binwidth = 5, fill = \"tomato\", color = \"black\", alpha = 0.7) +\n  labs(x = \"Age\", y = \"Count\", title = \"Age Distribution for All People and Heart Attack Patients\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nInsight 4\n\n\n\n\nAs we can see from the figure above, the proportion of people with the disease in each group of different exercise intensities is almost the same as the proportion of the overall number of people in their group, so there is no significant relationship between the two either.\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=select_data, \n       aes(x = Cholesterol_Level, \n           colour = Heart_Attack_Occurrence)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\nInsight 5\n\n\n\n\nLooking at the cholesterol density graph of the respondents above, there is no significant difference between those at risk for heart disease and the healthy population. It can be seen that cholesterol levels are not a major potential cause of heart disease in Japan.\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(select_data, \n       aes(x = BMI, \n           y = Heart_Attack_Occurrence)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"BMI VS Heart Attack\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\nInsight 6\n\n\n\n\nThe BMI ridgeline models for the general population and the diseased population are nearly identical, and ostensibly their differences are not significant enough for a significant relationship to exist.\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nselect_data %&gt;%\n  ggplot(aes(x = Heart_Attack_Occurrence, \n             y = Stress_Levels)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean stress level\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\nInsight 7\n\n\n\n\nThe confidence intervals for the stress levels of the diseased and normal populations are nearly the same, and ostensibly the differences were not significant.\n\n\n\n\n\n\n\nAccording to existing studies, in general, factors such as age, blood glucose, blood pressure, etc., can be potential factors for developing heart disease, but the present dataset does not present any variables that are clearly associated with heart disease, which is a very strange matter. Based on the above results, I make the following speculation:\n\nThe form of the dataset may be not suitable for analyzing heart disease\nThe Japanese have a low incidence of cardiovascular disease worldwide, and their healthy lifestyle may make the role of these potentially heart disease-causing variables less pronounced\nGiven the complexity of the causative factors of heart disease, it may not be possible to analyze the relationship of only one pair of variables to derive valid insights, so subsequent logistic regression models or decision trees may be used to further analyze the dataset and incorporate additional medical information to determine the weight of these potential causative factors.\n\n\n\n\nhttps://atm.amegroups.org/article/view/10896/11530\nhttps://www.kaggle.com/datasets/ashaychoudhary/heart-attack-in-japan-youth-vs-adult"
  },
  {
    "objectID": "Take-home_exercise/Take-home_exercise_1.html#introduction",
    "href": "Take-home_exercise/Take-home_exercise_1.html#introduction",
    "title": "Take-home exercise 1",
    "section": "",
    "text": "With the rising prevalence of cardiovascular diseases worldwide, public attention to these conditions has also increased. Therefore, using data to identify risk factors for heart disease is crucial. This dataset focuses on Japanese citizens, recording their health status, risk factors, and personal conditions to explore potential insights within the data.\n\n\n\nThis take-home exercise aims to apply appropriate Exploratory Data Analysis (EDA) methods and ggplot2 functions to analyze the data. Based on the analysis and observations, it also briefly suggests potential insights for future research to help policymakers improve public healthcare."
  },
  {
    "objectID": "Take-home_exercise/Take-home_exercise_1.html#data-prepare",
    "href": "Take-home_exercise/Take-home_exercise_1.html#data-prepare",
    "title": "Take-home exercise 1",
    "section": "",
    "text": "Package\nfunction\n\n\n\n\nggplot2\nFor data visualization, creating high-quality charts.\n\n\ndplyr\nFor data manipulation, providing efficient filtering, transformation, and summarization functions.\n\n\nscales\nFor adjusting scales, axes, and formatting in ggplot2 charts.\n\n\ntidyverse\nA collection of data science packages, for data processing and visualization.\n\n\nggridges\nFor creating ridge plots, useful for visualizing density distributions.\n\n\ncolorspace\nFor advanced color management, including color transformations and palette selection.\n\n\nplotly\nFor creating interactive charts, including 3D and dynamic visualizations.\n\n\ncrosstalk\nFor enabling interactive data sharing between different HTML widgets (e.g., plotly, DT tables).\n\n\nDT\nFor creating interactive HTML data tables.\n\n\nggdist\nFor statistical visualizations, such as distributions and uncertainty representations.\n\n\ngganimate\nFor animating ggplot2 charts, enabling time-series or dynamic visualizations.\n\n\n\n\npacman::p_load(ggplot2, dplyr, scales, tidyverse, ggridges, colorspace, plotly, crosstalk, DT, ggdist, gganimate) \n\n\n\n\nThe dataset comes from Kaggle, with 1 table, 32 columns, and 30,000 rows. Each row of data represents the basic physical condition of a Japanese citizen.\n\n\n\n\nheart_attack_data &lt;- read.csv(\"data/japan_heart_attack_dataset.csv\")\n\n\n\n\nCheck the data set for duplicate data to prevent interference with subsequent analysis.\n\nheart_attack_data[duplicated(heart_attack_data), ]\n\n [1] Age                     Gender                  Region                 \n [4] Smoking_History         Diabetes_History        Hypertension_History   \n [7] Cholesterol_Level       Physical_Activity       Diet_Quality           \n[10] Alcohol_Consumption     Stress_Levels           BMI                    \n[13] Heart_Rate              Systolic_BP             Diastolic_BP           \n[16] Family_History          Heart_Attack_Occurrence Extra_Column_1         \n[19] Extra_Column_2          Extra_Column_3          Extra_Column_4         \n[22] Extra_Column_5          Extra_Column_6          Extra_Column_7         \n[25] Extra_Column_8          Extra_Column_9          Extra_Column_10        \n[28] Extra_Column_11         Extra_Column_12         Extra_Column_13        \n[31] Extra_Column_14         Extra_Column_15        \n&lt;0 rows&gt; (or 0-length row.names)\n\n\nThe result shows no duplicate data.\n\n\n\nAccording to Fabian Sanchis-Gomar. (2016). Epidemiology of coronary heart disease and acute coronary syndrome. This analysis will focus on the following factors:\n\n\n\n\n\n\n\n\n\nNo\nName\nDescription\nType of Variable\n\n\n\n\n1\nAge\nAge of respondents\nNumerical\n\n\n2\nGender\nMale or Female\nCategorical\n\n\n3\nSmoking History\nYes or No\nCategorical\n\n\n4\nDiabetes History\nYes or No\nCategorical\n\n\n5\nPhysical Activity\nIntensity level of physical activity\nNumerical\n\n\n6\nCholesterol_Level\nCholesterol levels of respondents\nNumerical\n\n\n7\nStress Level\nStress Level of respondents\nNumerical\n\n\n8\nBMI\nWeight / Height ², used to determine the weight health status of respondents\nNumerical\n\n\n9\nFamily History\nYes or No\nCategorical\n\n\n10\nHeart Attack Occurrence\nYes or No\nCategorical\n\n\n\nTherefore, only relevant columns are selected for analysis.\n\nselect_data &lt;- heart_attack_data %&gt;% select (Age, Gender, Smoking_History, Diabetes_History, Physical_Activity, Cholesterol_Level, Stress_Levels, BMI, Family_History, Heart_Attack_Occurrence )\n\nUse the code to perform checks on the newly generated dataset.\n\nglimpse(select_data)\n\nRows: 30,000\nColumns: 10\n$ Age                     &lt;int&gt; 56, 69, 46, 32, 60, 25, 78, 38, 56, 75, 36, 40…\n$ Gender                  &lt;chr&gt; \"Male\", \"Male\", \"Male\", \"Female\", \"Female\", \"F…\n$ Smoking_History         &lt;chr&gt; \"Yes\", \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"Y…\n$ Diabetes_History        &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No…\n$ Physical_Activity       &lt;chr&gt; \"Moderate\", \"Low\", \"Low\", \"Moderate\", \"High\", …\n$ Cholesterol_Level       &lt;dbl&gt; 186.4002, 185.1367, 210.6966, 211.1655, 223.81…\n$ Stress_Levels           &lt;dbl&gt; 3.644786, 3.384056, 3.810911, 6.014878, 6.8068…\n$ BMI                     &lt;dbl&gt; 33.96135, 28.24287, 27.60121, 23.71729, 19.771…\n$ Family_History          &lt;chr&gt; \"No\", \"Yes\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No…\n$ Heart_Attack_Occurrence &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n\n\n\n\n\n\nany(is.na(select_data))\n\n[1] FALSE\n\n\nThe result shows no missing values."
  },
  {
    "objectID": "Take-home_exercise/Take-home_exercise_1.html#insights",
    "href": "Take-home_exercise/Take-home_exercise_1.html#insights",
    "title": "Take-home exercise 1",
    "section": "",
    "text": "Since the number of respondents in each age group is not necessarily the same (i.e., the age distribution is not necessarily balanced), it is also necessary to consider the age distribution of the respondents.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(select_data, aes(x = Age)) +\n  geom_histogram(data = select_data, aes(x = Age), binwidth = 5, fill = \"lightgray\", color = \"black\", alpha = 0.5) +\n  geom_histogram(data = subset(select_data, Heart_Attack_Occurrence == \"Yes\"), aes(x = Age), binwidth = 5, fill = \"tomato\", color = \"black\", alpha = 0.7) +\n  labs(x = \"Age\", y = \"Count\", title = \"Age Distribution for All People and Heart Attack Patients\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nInsight 1\n\n\n\n\nAs we can see from the graph above, there is no significant relationship between whether or not a person has heart disease and their age in Japan. The distribution of the number of people with heart disease does not change significantly with age, and the number of people with heart disease is basically the same as the age distribution of the respondents.\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(scales)\ndata_summary &lt;- select_data %&gt;%\n  group_by(Heart_Attack_Occurrence, Gender) %&gt;%\n  summarise(count = n()) %&gt;%\n  ungroup() %&gt;%\n  mutate(total_count = sum(count), percentage = count / total_count)\n\nggplot(data_summary, aes(x = \"\", y = count, fill = interaction(Heart_Attack_Occurrence, Gender))) +\n  geom_bar(stat = \"identity\", width = 1, color = \"white\") +\n  coord_polar(theta = \"y\") +  \n  labs(title = \"Heart Attack Occurrence vs Gender\", fill = \"Heart Attack Occurrence and Gender\") +\n  theme_void() +  \n  scale_fill_manual(values = c(\"lightcoral\", \"salmon\", \"lightsteelblue\", \"skyblue\")) +\n  geom_text(aes(label = percent(percentage)), position = position_stack(vjust = 0.5), color = \"black\")\n\n\n\n\n\n\n\n\n\n\nInsight 2\n\n\n\n\nFrom the above figure, we can see that the proportion of men and women with heart disease is almost the same when the ratio of men and women respondents is almost the same, so it can be seen that whether or not to suffer from heart disease has nothing to do with the gender of the patients in Japan.\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndf_prop &lt;- select_data %&gt;%\n  pivot_longer(cols = c(Diabetes_History, Smoking_History, Family_History),\n               names_to = \"Risk_Factor\",\n               values_to = \"Status\") %&gt;%\n  group_by(Risk_Factor, Status) %&gt;%\n  summarise(Heart_Attack_Rate = mean(Heart_Attack_Occurrence == \"Yes\")) %&gt;%\n  ungroup()\n\nggplot(df_prop, aes(x = Status, y = Heart_Attack_Rate, fill = Status)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  facet_wrap(~ Risk_Factor) +\n  theme_minimal() +\n  labs(title = \"Heart Attack Occurrence by Risk Factors\",\n       x = \"Risk Factor Status (Yes/No)\",\n       y = \"Heart Attack Occurrence Rate\",\n       fill = \"Risk Factor Status\") +\n  scale_y_continuous(labels = scales::percent) +  # Convert Y-axis to percentage\n  scale_fill_manual(values = c(\"No\" = \"skyblue\", \"Yes\" = \"lightcoral\"))\n\n\n\n\n\n\n\n\n\n\nInsight 3\n\n\n\n\nAs we can see from the graph above, people with diabetes and a history of smoking are a bit more likely to get heart disease than the general population in Japan, but the overall percentage difference is not significant..\n\n\n\n\n\n\nBecause the number of people at different exercise intensities is itself different, the ratio of their numbers will also be considered.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(select_data, aes(x = Physical_Activity)) +\n  geom_bar(data = select_data, aes(x = Physical_Activity), binwidth = 5, fill = \"lightgray\", color = \"black\", alpha = 0.5) +\n  geom_bar(data = subset(select_data, Heart_Attack_Occurrence == \"Yes\"), aes(x = Physical_Activity), binwidth = 5, fill = \"tomato\", color = \"black\", alpha = 0.7) +\n  labs(x = \"Age\", y = \"Count\", title = \"Age Distribution for All People and Heart Attack Patients\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nInsight 4\n\n\n\n\nAs we can see from the figure above, the proportion of people with the disease in each group of different exercise intensities is almost the same as the proportion of the overall number of people in their group, so there is no significant relationship between the two either.\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=select_data, \n       aes(x = Cholesterol_Level, \n           colour = Heart_Attack_Occurrence)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\nInsight 5\n\n\n\n\nLooking at the cholesterol density graph of the respondents above, there is no significant difference between those at risk for heart disease and the healthy population. It can be seen that cholesterol levels are not a major potential cause of heart disease in Japan.\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(select_data, \n       aes(x = BMI, \n           y = Heart_Attack_Occurrence)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"BMI VS Heart Attack\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\nInsight 6\n\n\n\n\nThe BMI ridgeline models for the general population and the diseased population are nearly identical, and ostensibly their differences are not significant enough for a significant relationship to exist.\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nselect_data %&gt;%\n  ggplot(aes(x = Heart_Attack_Occurrence, \n             y = Stress_Levels)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean stress level\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\nInsight 7\n\n\n\n\nThe confidence intervals for the stress levels of the diseased and normal populations are nearly the same, and ostensibly the differences were not significant."
  },
  {
    "objectID": "Take-home_exercise/Take-home_exercise_1.html#summary-and-conclusion",
    "href": "Take-home_exercise/Take-home_exercise_1.html#summary-and-conclusion",
    "title": "Take-home exercise 1",
    "section": "",
    "text": "According to existing studies, in general, factors such as age, blood glucose, blood pressure, etc., can be potential factors for developing heart disease, but the present dataset does not present any variables that are clearly associated with heart disease, which is a very strange matter. Based on the above results, I make the following speculation:\n\nThe form of the dataset may be not suitable for analyzing heart disease\nThe Japanese have a low incidence of cardiovascular disease worldwide, and their healthy lifestyle may make the role of these potentially heart disease-causing variables less pronounced\nGiven the complexity of the causative factors of heart disease, it may not be possible to analyze the relationship of only one pair of variables to derive valid insights, so subsequent logistic regression models or decision trees may be used to further analyze the dataset and incorporate additional medical information to determine the weight of these potential causative factors."
  },
  {
    "objectID": "Take-home_exercise/Take-home_exercise_1.html#references",
    "href": "Take-home_exercise/Take-home_exercise_1.html#references",
    "title": "Take-home exercise 1",
    "section": "",
    "text": "https://atm.amegroups.org/article/view/10896/11530\nhttps://www.kaggle.com/datasets/ashaychoudhary/heart-attack-in-japan-youth-vs-adult"
  }
]